{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7405399,"sourceType":"datasetVersion","datasetId":4306525},{"sourceId":8588058,"sourceType":"datasetVersion","datasetId":5136800}],"dockerImageVersionId":30733,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU"},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras import datasets, layers, models\nimport matplotlib.pyplot as plt\n\nimport pandas as pd\nimport math, random\nimport torch\nimport torchaudio\nfrom torchaudio import transforms\nfrom IPython.display import Audio\n\nfrom torch.utils.data import DataLoader, Dataset, random_split\nimport torch.nn.functional as F\nfrom torch.nn import init\nimport torch\nimport torchvision\nimport torch.nn as nn","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","id":"VADzFxBK3pvV","execution":{"iopub.status.busy":"2024-06-12T02:00:55.231016Z","iopub.execute_input":"2024-06-12T02:00:55.231389Z","iopub.status.idle":"2024-06-12T02:01:14.683524Z","shell.execute_reply.started":"2024-06-12T02:00:55.231338Z","shell.execute_reply":"2024-06-12T02:01:14.682637Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"2024-06-12 02:00:57.212529: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-06-12 02:00:57.212676: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-06-12 02:00:57.360284: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"path = \"/kaggle/input/autism-paper-data/Retained/dataset_file_directory.csv\"\ndf_original = pd.read_csv(path)\ndf_original.head()","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":224},"id":"TT8NyeNb3pvW","outputId":"ce3c6c65-5677-45ba-adeb-eb2ba27bb9da","execution":{"iopub.status.busy":"2024-06-12T02:01:14.685496Z","iopub.execute_input":"2024-06-12T02:01:14.686041Z","iopub.status.idle":"2024-06-12T02:01:14.731078Z","shell.execute_reply.started":"2024-06-12T02:01:14.686007Z","shell.execute_reply":"2024-06-12T02:01:14.730214Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"                                    Filename Participant   Label\n0   210408_2025_00-01-38.27--00-01-40.84.wav         P01  social\n1   210324_2036_00-06-03.61--00-06-05.78.wav         P01  social\n2   210324_2036_00-09-04.66--00-09-06.16.wav         P01  social\n3     210324_2036_00-11-18.6--00-11-20.3.wav         P01  social\n4  200506_2110_00-01-25.92--00-01-26.58c.wav         P01  social","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Filename</th>\n      <th>Participant</th>\n      <th>Label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>210408_2025_00-01-38.27--00-01-40.84.wav</td>\n      <td>P01</td>\n      <td>social</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>210324_2036_00-06-03.61--00-06-05.78.wav</td>\n      <td>P01</td>\n      <td>social</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>210324_2036_00-09-04.66--00-09-06.16.wav</td>\n      <td>P01</td>\n      <td>social</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>210324_2036_00-11-18.6--00-11-20.3.wav</td>\n      <td>P01</td>\n      <td>social</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>200506_2110_00-01-25.92--00-01-26.58c.wav</td>\n      <td>P01</td>\n      <td>social</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df_original.shape[0]","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"arHNYdz73pvW","outputId":"9a772341-4256-4365-d283-f7c88372767d","execution":{"iopub.status.busy":"2024-06-12T02:01:14.732544Z","iopub.execute_input":"2024-06-12T02:01:14.733264Z","iopub.status.idle":"2024-06-12T02:01:14.785709Z","shell.execute_reply.started":"2024-06-12T02:01:14.733194Z","shell.execute_reply":"2024-06-12T02:01:14.784629Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"6450"},"metadata":{}}]},{"cell_type":"code","source":"df_original.Label.unique() #Print unique types of sound","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YviFCFY33pvW","outputId":"4fdd27a5-f50a-4cfb-d407-9240255c4d09","execution":{"iopub.status.busy":"2024-06-12T02:01:14.787014Z","iopub.execute_input":"2024-06-12T02:01:14.787402Z","iopub.status.idle":"2024-06-12T02:01:14.798990Z","shell.execute_reply.started":"2024-06-12T02:01:14.787354Z","shell.execute_reply":"2024-06-12T02:01:14.798109Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"array(['social', 'selftalk', 'request', 'delighted', 'dysregulated',\n       'frustrated'], dtype=object)"},"metadata":{}}]},{"cell_type":"code","source":"df_original['Label'].value_counts() #Number of datapoints available for each target variable","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_u6939Pt3pvX","outputId":"0c23ca54-7b67-442a-8b43-145ccb3a8755","execution":{"iopub.status.busy":"2024-06-12T02:01:14.801719Z","iopub.execute_input":"2024-06-12T02:01:14.802535Z","iopub.status.idle":"2024-06-12T02:01:14.819172Z","shell.execute_reply.started":"2024-06-12T02:01:14.802496Z","shell.execute_reply":"2024-06-12T02:01:14.818101Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"Label\nselftalk        1885\nfrustrated      1536\ndelighted       1272\ndysregulated     704\nsocial           634\nrequest          419\nName: count, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"df_original[\"classID\"] = df_original['Label']\ndf_original['classID'].replace(['selftalk', 'frustrated', 'delighted', 'dysregulated', 'social', 'request'],\n                        [0, 1, 2, 3, 4, 5], inplace=True)\n","metadata":{"id":"9YhoQu9P3pvX","execution":{"iopub.status.busy":"2024-06-12T02:01:14.820466Z","iopub.execute_input":"2024-06-12T02:01:14.820786Z","iopub.status.idle":"2024-06-12T02:01:14.835513Z","shell.execute_reply.started":"2024-06-12T02:01:14.820761Z","shell.execute_reply":"2024-06-12T02:01:14.834523Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_34/1495406677.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  df_original['classID'].replace(['selftalk', 'frustrated', 'delighted', 'dysregulated', 'social', 'request'],\n/tmp/ipykernel_34/1495406677.py:2: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n  df_original['classID'].replace(['selftalk', 'frustrated', 'delighted', 'dysregulated', 'social', 'request'],\n","output_type":"stream"}]},{"cell_type":"code","source":"df = df_original\ndf = df.drop(['Participant', 'Label'], axis=1)\ndf.head()","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"BhnV5Z313pvX","outputId":"87e6fe8f-5605-4172-b32e-1610bd28a76e","execution":{"iopub.status.busy":"2024-06-12T02:01:14.837108Z","iopub.execute_input":"2024-06-12T02:01:14.837466Z","iopub.status.idle":"2024-06-12T02:01:14.852273Z","shell.execute_reply.started":"2024-06-12T02:01:14.837432Z","shell.execute_reply":"2024-06-12T02:01:14.851326Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"                                    Filename  classID\n0   210408_2025_00-01-38.27--00-01-40.84.wav        4\n1   210324_2036_00-06-03.61--00-06-05.78.wav        4\n2   210324_2036_00-09-04.66--00-09-06.16.wav        4\n3     210324_2036_00-11-18.6--00-11-20.3.wav        4\n4  200506_2110_00-01-25.92--00-01-26.58c.wav        4","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Filename</th>\n      <th>classID</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>210408_2025_00-01-38.27--00-01-40.84.wav</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>210324_2036_00-06-03.61--00-06-05.78.wav</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>210324_2036_00-09-04.66--00-09-06.16.wav</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>210324_2036_00-11-18.6--00-11-20.3.wav</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>200506_2110_00-01-25.92--00-01-26.58c.wav</td>\n      <td>4</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df['classID'].value_counts() #Number of datapoints available for each target variable","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7dF5uZe63pvX","outputId":"315b25f7-159b-4d66-bd39-adff125bcc6c","execution":{"iopub.status.busy":"2024-06-12T02:01:14.853439Z","iopub.execute_input":"2024-06-12T02:01:14.853712Z","iopub.status.idle":"2024-06-12T02:01:14.868767Z","shell.execute_reply.started":"2024-06-12T02:01:14.853688Z","shell.execute_reply":"2024-06-12T02:01:14.867690Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"classID\n0    1885\n1    1536\n2    1272\n3     704\n4     634\n5     419\nName: count, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"# Construct file path by concatenating fold and file name\ndf['relative_path'] = '/' + df['Filename'].astype(str)\n\n# Take relevant columns\ndf = df[['relative_path', 'classID']]\ndf.head()","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"nwo3h2H03pvX","outputId":"efda33bd-0fcc-4620-8eb1-7f83eba15525","execution":{"iopub.status.busy":"2024-06-12T02:01:14.869959Z","iopub.execute_input":"2024-06-12T02:01:14.870227Z","iopub.status.idle":"2024-06-12T02:01:14.888079Z","shell.execute_reply.started":"2024-06-12T02:01:14.870201Z","shell.execute_reply":"2024-06-12T02:01:14.887067Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"                                relative_path  classID\n0   /210408_2025_00-01-38.27--00-01-40.84.wav        4\n1   /210324_2036_00-06-03.61--00-06-05.78.wav        4\n2   /210324_2036_00-09-04.66--00-09-06.16.wav        4\n3     /210324_2036_00-11-18.6--00-11-20.3.wav        4\n4  /200506_2110_00-01-25.92--00-01-26.58c.wav        4","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>relative_path</th>\n      <th>classID</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>/210408_2025_00-01-38.27--00-01-40.84.wav</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>/210324_2036_00-06-03.61--00-06-05.78.wav</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>/210324_2036_00-09-04.66--00-09-06.16.wav</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>/210324_2036_00-11-18.6--00-11-20.3.wav</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>/200506_2110_00-01-25.92--00-01-26.58c.wav</td>\n      <td>4</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"#Random shuffle of rows.\ndf = df. sample(frac=1)\ndf.head()","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"QkOyOoUS3pvX","outputId":"11164c33-f8a0-43cb-a9a5-ca01a634fe46","execution":{"iopub.status.busy":"2024-06-12T02:01:14.889311Z","iopub.execute_input":"2024-06-12T02:01:14.889703Z","iopub.status.idle":"2024-06-12T02:01:14.906311Z","shell.execute_reply.started":"2024-06-12T02:01:14.889656Z","shell.execute_reply":"2024-06-12T02:01:14.905417Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"                                   relative_path  classID\n1643  /200603_2227_00-06-41.03--00-06-43.21c.wav        2\n4562   /210130_2120_00-05-17.43--00-05-18.2c.wav        4\n4645   /210131_0922_00-17-29.81--00-17-30.57.wav        5\n1779   /200905_1630_00-00-21.95--00-00-22.58.wav        2\n2785  /200906_1558_00-08-06.69--00-08-07.96c.wav        3","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>relative_path</th>\n      <th>classID</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1643</th>\n      <td>/200603_2227_00-06-41.03--00-06-43.21c.wav</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4562</th>\n      <td>/210130_2120_00-05-17.43--00-05-18.2c.wav</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>4645</th>\n      <td>/210131_0922_00-17-29.81--00-17-30.57.wav</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>1779</th>\n      <td>/200905_1630_00-00-21.95--00-00-22.58.wav</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2785</th>\n      <td>/200906_1558_00-08-06.69--00-08-07.96c.wav</td>\n      <td>3</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"#Function to read and load the audio files in '.wav' format using Pytorch.\nclass AudioUtil():\n  @staticmethod\n  def open(audio_file):\n    sig, sr = torchaudio.load(audio_file) # Load an audio file. Return the signal as a tensor and the sample rate\n    return (sig, sr)\n\n\n#Refer tutotial file for explaination about the following blocks of code: -\n  def rechannel(aud, new_channel):\n    sig, sr = aud\n    if (sig.shape[0] == new_channel):\n      return aud\n    if (new_channel == 1):\n      resig = sig[:1, :]\n    else:\n      resig = torch.cat([sig, sig])\n    return ((resig, sr))\n\n  def resample(aud, newsr):\n    sig, sr = aud\n    if (sr == newsr):\n      return aud\n    num_channels = sig.shape[0]\n    resig = torchaudio.transforms.Resample(sr, newsr)(sig[:1,:])\n    if (num_channels > 1):\n      retwo = torchaudio.transforms.Resample(sr, newsr)(sig[1:,:])\n      resig = torch.cat([resig, retwo])\n    return ((resig, newsr))\n\n  def pad_trunc(aud, max_ms):\n    sig, sr = aud\n    num_rows, sig_len = sig.shape\n    max_len = sr//1000 * max_ms\n    if (sig_len > max_len):\n      sig = sig[:,:max_len]\n    elif (sig_len < max_len):\n      pad_begin_len = random.randint(0, max_len - sig_len)\n      pad_end_len = max_len - sig_len - pad_begin_len\n      pad_begin = torch.zeros((num_rows, pad_begin_len))\n      pad_end = torch.zeros((num_rows, pad_end_len))\n      sig = torch.cat((pad_begin, sig, pad_end), 1)\n    return (sig, sr)\n\n  def time_shift(aud, shift_limit):\n    sig,sr = aud\n    _, sig_len = sig.shape\n    shift_amt = int(random.random() * shift_limit * sig_len)\n    return (sig.roll(shift_amt), sr)\n\n  def spectro_gram(aud, n_mels=64, n_fft=1024, hop_len=None):\n    sig,sr = aud\n    top_db = 80\n    spec = transforms.MelSpectrogram(sr, n_fft=n_fft, hop_length=hop_len, n_mels=n_mels)(sig)\n    spec = transforms.AmplitudeToDB(top_db=top_db)(spec)\n    return (spec)\n\n  def spectro_augment(spec, max_mask_pct=0.1, n_freq_masks=1, n_time_masks=1):\n    _, n_mels, n_steps = spec.shape\n    mask_value = spec.mean()\n    aug_spec = spec\n    freq_mask_param = max_mask_pct * n_mels\n    for _ in range(n_freq_masks):\n      aug_spec = transforms.FrequencyMasking(freq_mask_param)(aug_spec, mask_value)\n    time_mask_param = max_mask_pct * n_steps\n    for _ in range(n_time_masks):\n      aug_spec = transforms.TimeMasking(time_mask_param)(aug_spec, mask_value)\n    return aug_spec","metadata":{"id":"r0T87xD-3pvX","execution":{"iopub.status.busy":"2024-06-12T02:01:14.907784Z","iopub.execute_input":"2024-06-12T02:01:14.908090Z","iopub.status.idle":"2024-06-12T02:01:14.926315Z","shell.execute_reply.started":"2024-06-12T02:01:14.908063Z","shell.execute_reply":"2024-06-12T02:01:14.925319Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"class SoundDS(Dataset):\n  def __init__(self, df, data_path):\n    self.df = df\n    self.data_path = str(data_path)\n    self.duration = 4000\n    self.sr = 44100\n    self.channel = 2\n    self.shift_pct = 0.4\n\n  #Number of items in dataset\n  def __len__(self):\n    return len(self.df)\n\n\n  #Get i'th item in dataset\n  def __getitem__(self, idx):\n    #Absolute file path of the audio file = audio directory + relative path\n    audio_file = self.data_path + self.df.loc[idx, 'relative_path']\n    #Get the Class ID\n    class_id = self.df.loc[idx, 'classID']\n\n    aud = AudioUtil.open(audio_file)\n    \"\"\"\n    Some sounds have a higher sample rate, or fewer channels compared to the\n    majority. So make all sounds have the same number of channels and same\n    sample rate. Unless the sample rate is the same, the pad_trunc will still\n    result in arrays of different lengths, even though the sound duration is\n    the same.\n    \"\"\"\n    reaud = AudioUtil.resample(aud, self.sr)\n    rechan = AudioUtil.rechannel(reaud, self.channel)\n\n\n    dur_aud = AudioUtil.pad_trunc(rechan, self.duration)\n    shift_aud = AudioUtil.time_shift(dur_aud, self.shift_pct)\n    sgram = AudioUtil.spectro_gram(shift_aud, n_mels=64, n_fft=1024, hop_len=None)\n    aug_sgram = AudioUtil.spectro_augment(sgram, max_mask_pct=0.1, n_freq_masks=2, n_time_masks=2)\n\n    return aug_sgram, class_id","metadata":{"id":"0Ta5Jm_C3pvY","execution":{"iopub.status.busy":"2024-06-12T02:01:14.927455Z","iopub.execute_input":"2024-06-12T02:01:14.927730Z","iopub.status.idle":"2024-06-12T02:01:14.941027Z","shell.execute_reply.started":"2024-06-12T02:01:14.927705Z","shell.execute_reply":"2024-06-12T02:01:14.940112Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"data_path = \"/kaggle/input/autism-paper-data/Retained/audio\"\nmyds = SoundDS(df, data_path)\n#myds = SoundDS(df, path)\n\n#Random split of 80:20 between training and validation\nnum_items = len(myds)\nnum_train = round(num_items * 0.8)\nnum_val = num_items - num_train\ntrain_ds, val_ds = random_split(myds, [num_train, num_val])\n\n#Create training and validation data loaders\ntrain_dl = torch.utils.data.DataLoader(train_ds, batch_size=16, shuffle=True)\nval_dl = torch.utils.data.DataLoader(val_ds, batch_size=16, shuffle=False)","metadata":{"id":"r4NNkorW3pvY","execution":{"iopub.status.busy":"2024-06-12T02:01:14.942305Z","iopub.execute_input":"2024-06-12T02:01:14.942837Z","iopub.status.idle":"2024-06-12T02:01:14.968813Z","shell.execute_reply.started":"2024-06-12T02:01:14.942803Z","shell.execute_reply":"2024-06-12T02:01:14.967766Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"print(num_items, num_train, num_val)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xQyDBpcP3pvY","outputId":"3ba4167d-a0e3-4b3f-8179-53ca313ddbe2","execution":{"iopub.status.busy":"2024-06-12T02:01:14.973340Z","iopub.execute_input":"2024-06-12T02:01:14.973696Z","iopub.status.idle":"2024-06-12T02:01:14.978886Z","shell.execute_reply.started":"2024-06-12T02:01:14.973668Z","shell.execute_reply":"2024-06-12T02:01:14.977645Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"6450 5160 1290\n","output_type":"stream"}]},{"cell_type":"code","source":"type(train_dl)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":291},"id":"sDjUmJPV3pvY","outputId":"cefd97a9-7de2-4774-8d4e-27ae2967f47c","execution":{"iopub.status.busy":"2024-06-12T02:01:14.980294Z","iopub.execute_input":"2024-06-12T02:01:14.980817Z","iopub.status.idle":"2024-06-12T02:01:14.990856Z","shell.execute_reply.started":"2024-06-12T02:01:14.980783Z","shell.execute_reply":"2024-06-12T02:01:14.989806Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"torch.utils.data.dataloader.DataLoader"},"metadata":{}}]},{"cell_type":"code","source":"from torchvision import models\n# DenseNet\nmodel = models.densenet161(pretrained=True)\nmodel.features.conv0 = nn.Conv2d(2, model.features.conv0.out_channels,\n                                 kernel_size=model.features.conv0.kernel_size,\n                                 stride=model.features.conv0.stride,\n                                 padding=model.features.conv0.padding)\nnum_ftrs = model.classifier.in_features\nmodel.classifier = nn.Linear(num_ftrs, df_original['classID'].nunique())\n\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nmyModel = model.to(device)","metadata":{"id":"cqMXmajY3pvY","execution":{"iopub.status.busy":"2024-06-12T02:01:14.992188Z","iopub.execute_input":"2024-06-12T02:01:14.992600Z","iopub.status.idle":"2024-06-12T02:01:16.934474Z","shell.execute_reply.started":"2024-06-12T02:01:14.992566Z","shell.execute_reply":"2024-06-12T02:01:16.933578Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet161_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet161_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\nDownloading: \"https://download.pytorch.org/models/densenet161-8d451a50.pth\" to /root/.cache/torch/hub/checkpoints/densenet161-8d451a50.pth\n100%|██████████| 110M/110M [00:00<00:00, 154MB/s]  \n","output_type":"stream"}]},{"cell_type":"code","source":"def training(model, train_dl, num_epochs):\n  criterion = nn.CrossEntropyLoss()\n  optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n  scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=0.0001,\n                                                  steps_per_epoch=int(len(train_dl)),\n                                                  epochs=num_epochs,\n                                                  anneal_strategy='linear')\n\n  for epoch in range(num_epochs):\n    running_loss = 0.0\n    correct_prediction = 0\n    total_prediction = 0\n\n    for i, data in enumerate(train_dl):\n      inputs, labels = data[0].to(device), data[1].to(device)\n      inputs_m, inputs_s = inputs.mean(), inputs.std()\n      inputs = (inputs - inputs_m) / inputs_s\n\n      optimizer.zero_grad()\n      outputs = model(inputs)\n      loss = criterion(outputs, labels)\n      loss.backward()\n      optimizer.step()\n      scheduler.step()\n\n      running_loss += loss.item()\n      _, prediction = torch.max(outputs, 1)\n      correct_prediction += (prediction == labels).sum().item()\n      total_prediction += prediction.shape[0]\n\n    avg_loss = running_loss / len(train_dl)\n    acc = correct_prediction / total_prediction\n    print(f'Epoch: {epoch}, Loss: {avg_loss:.2f}, Accuracy: {acc:.2f}')\n\n  print('Finished Training')","metadata":{"id":"kvUmCNmO3pvY","execution":{"iopub.status.busy":"2024-06-12T02:01:16.935861Z","iopub.execute_input":"2024-06-12T02:01:16.936196Z","iopub.status.idle":"2024-06-12T02:01:16.946757Z","shell.execute_reply.started":"2024-06-12T02:01:16.936169Z","shell.execute_reply":"2024-06-12T02:01:16.945641Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"def inference(model, val_dl):\n  correct_prediction = 0\n  total_prediction = 0\n\n  with torch.no_grad():\n    for data in val_dl:\n      inputs, labels = data[0].to(device), data[1].to(device)\n      inputs_m, inputs_s = inputs.mean(), inputs.std()\n      inputs = (inputs - inputs_m) / inputs_s\n      outputs = model(inputs)\n      _, prediction = torch.max(outputs, 1)\n      correct_prediction += (prediction == labels).sum().item()\n      total_prediction += prediction.shape[0]\n\n  acc = correct_prediction / total_prediction\n  print(f'Accuracy: {acc:.2f}, Total items: {total_prediction}')","metadata":{"id":"vzChmioM3pvY","execution":{"iopub.status.busy":"2024-06-12T02:01:16.947848Z","iopub.execute_input":"2024-06-12T02:01:16.948112Z","iopub.status.idle":"2024-06-12T02:01:16.958449Z","shell.execute_reply.started":"2024-06-12T02:01:16.948090Z","shell.execute_reply":"2024-06-12T02:01:16.957424Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"num_epochs = 50\ntraining(myModel, train_dl, num_epochs)\ninference(myModel, val_dl)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":329},"id":"2SOyLCB43pvY","outputId":"acb4e364-bcdd-41a8-f816-73f2b65fd7cf","execution":{"iopub.status.busy":"2024-06-12T02:01:16.959604Z","iopub.execute_input":"2024-06-12T02:01:16.959897Z","iopub.status.idle":"2024-06-12T03:44:32.688373Z","shell.execute_reply.started":"2024-06-12T02:01:16.959873Z","shell.execute_reply":"2024-06-12T03:44:32.687180Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"Epoch: 0, Loss: 1.69, Accuracy: 0.28\nEpoch: 1, Loss: 1.54, Accuracy: 0.38\nEpoch: 2, Loss: 1.43, Accuracy: 0.44\nEpoch: 3, Loss: 1.32, Accuracy: 0.50\nEpoch: 4, Loss: 1.24, Accuracy: 0.54\nEpoch: 5, Loss: 1.19, Accuracy: 0.55\nEpoch: 6, Loss: 1.14, Accuracy: 0.58\nEpoch: 7, Loss: 1.12, Accuracy: 0.58\nEpoch: 8, Loss: 1.07, Accuracy: 0.61\nEpoch: 9, Loss: 1.03, Accuracy: 0.62\nEpoch: 10, Loss: 1.01, Accuracy: 0.63\nEpoch: 11, Loss: 0.99, Accuracy: 0.64\nEpoch: 12, Loss: 0.96, Accuracy: 0.64\nEpoch: 13, Loss: 0.93, Accuracy: 0.67\nEpoch: 14, Loss: 0.92, Accuracy: 0.66\nEpoch: 15, Loss: 0.88, Accuracy: 0.68\nEpoch: 16, Loss: 0.84, Accuracy: 0.69\nEpoch: 17, Loss: 0.79, Accuracy: 0.71\nEpoch: 18, Loss: 0.75, Accuracy: 0.73\nEpoch: 19, Loss: 0.73, Accuracy: 0.73\nEpoch: 20, Loss: 0.67, Accuracy: 0.76\nEpoch: 21, Loss: 0.64, Accuracy: 0.77\nEpoch: 22, Loss: 0.61, Accuracy: 0.78\nEpoch: 23, Loss: 0.55, Accuracy: 0.80\nEpoch: 24, Loss: 0.53, Accuracy: 0.81\nEpoch: 25, Loss: 0.49, Accuracy: 0.82\nEpoch: 26, Loss: 0.44, Accuracy: 0.83\nEpoch: 27, Loss: 0.41, Accuracy: 0.85\nEpoch: 28, Loss: 0.38, Accuracy: 0.87\nEpoch: 29, Loss: 0.38, Accuracy: 0.87\nEpoch: 30, Loss: 0.32, Accuracy: 0.88\nEpoch: 31, Loss: 0.30, Accuracy: 0.89\nEpoch: 32, Loss: 0.28, Accuracy: 0.90\nEpoch: 33, Loss: 0.25, Accuracy: 0.91\nEpoch: 34, Loss: 0.23, Accuracy: 0.92\nEpoch: 35, Loss: 0.22, Accuracy: 0.92\nEpoch: 36, Loss: 0.21, Accuracy: 0.92\nEpoch: 37, Loss: 0.19, Accuracy: 0.93\nEpoch: 38, Loss: 0.18, Accuracy: 0.94\nEpoch: 39, Loss: 0.16, Accuracy: 0.94\nEpoch: 40, Loss: 0.14, Accuracy: 0.95\nEpoch: 41, Loss: 0.14, Accuracy: 0.95\nEpoch: 42, Loss: 0.14, Accuracy: 0.95\nEpoch: 43, Loss: 0.12, Accuracy: 0.96\nEpoch: 44, Loss: 0.11, Accuracy: 0.96\nEpoch: 45, Loss: 0.10, Accuracy: 0.97\nEpoch: 46, Loss: 0.09, Accuracy: 0.97\nEpoch: 47, Loss: 0.08, Accuracy: 0.97\nEpoch: 48, Loss: 0.09, Accuracy: 0.97\nEpoch: 49, Loss: 0.09, Accuracy: 0.97\nFinished Training\nAccuracy: 0.70, Total items: 1290\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.metrics import f1_score, roc_auc_score\nimport numpy as np\n\ndef inference(model, val_dl):\n    all_predictions = []\n    all_labels = []\n\n    # Disable gradient updates\n    with torch.no_grad():\n        for data in val_dl:\n            inputs, labels = data[0].to(device), data[1].to(device)\n\n            # Normalize the inputs\n            inputs_m, inputs_s = inputs.mean(), inputs.std()\n            inputs = (inputs - inputs_m) / inputs_s\n\n            # Get predictions\n            outputs = model(inputs)\n            _, predictions = torch.max(outputs, 1)\n\n            all_predictions.extend(predictions.cpu().numpy())\n            all_labels.extend(labels.cpu().numpy())\n\n    # Calculate metrics\n    accuracy = np.mean(np.array(all_predictions) == np.array(all_labels))\n    f1 = f1_score(all_labels, all_predictions, average='weighted')\n\n    print(f'Accuracy: {accuracy:.2f}, F1 Score: {f1:.2f}')\n\n# Run inference on trained model with the validation set\ninference(myModel, val_dl)","metadata":{"id":"myZMGSLv3pvY","outputId":"c4eb34fa-44a1-4c30-a094-ed9acbe0a88f","execution":{"iopub.status.busy":"2024-06-12T03:44:32.689726Z","iopub.execute_input":"2024-06-12T03:44:32.690032Z","iopub.status.idle":"2024-06-12T03:44:57.813045Z","shell.execute_reply.started":"2024-06-12T03:44:32.690005Z","shell.execute_reply":"2024-06-12T03:44:57.811908Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"Accuracy: 0.71, F1 Score: 0.70\n","output_type":"stream"}]}]}